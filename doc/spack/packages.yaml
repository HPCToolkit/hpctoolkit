# SPDX-FileCopyrightText: 2018-2024 Rice University
#
# SPDX-License-Identifier: CC-BY-4.0

#
#  packages.yaml
#
#  This file specifies the versions and variants for HPCToolkit's
#  dependency packages and serves as a common reference point for how
#  to build them.  It also specifies the paths or modules for system
#  build tools (cmake, python, etc) to avoid rebuilding them.
#
#  Put this file in one of spack's configuration scope directories:
#    1. <spack-root>/etc/spack -- applies to this spack repo
#    2. <home-dir>/.spack -- applies to any spack on this machine
#           for this user
#    3. any dir -- applies with 'spack -C dir' argument
#
#  There are three sections: (1) regular hpctoolkit dependency specs,
#  (2) GPU and MPI specs, and (3) system build tools: cmake, perl,
#  python and GCC.
#
#  See also:
#    https://spack.readthedocs.io/en/latest/configuration.html
#    https://spack.readthedocs.io/en/latest/build_settings.html
#
#  Last revised: July 11, 2023.
#
packages:

  # If you want to specify a generic target or a specific compiler for
  # all builds, then you can set those here.  For example, a generic
  # target might be useful for a shared install across multiple
  # machine types.
  #
  # generic families: aarch64, ppc64, ppc64le, x86_64
  #
  # Selecting a specific provider for a virtual package (eg, openmpi
  # for mpi) also goes here under 'all'.
  #
  # all:
  #   target: [x86_64]
  #   compiler: [gcc@8.5.0]
  #   providers:
  #     mpi: [openmpi]


  # Note: settings in this file are only preferences, not hard
  # requirements.  If spack chooses a different version or variant,
  # you can force spack to use your version with the new 'require:'
  # field.
  #
  # Require takes a single, full spec and supersedes both version and
  # variant and should always be quoted.  For example:
  #
  # all:
  #   require: "%gcc@9.3.0 target=x86_64"
  #
  # mpi:
  #   require: "mpich@4.0.2"
  #
  # dyninst:
  #   require: "@12.2.1 +openmp"


  #------------------------------------------------------------
  # 1 -- HPCToolkit Prerequisite Packages
  #------------------------------------------------------------

  # This section contains hpctoolkit's prerequisites, recommended
  # versions and necessary variants.  Packages in this section should
  # normally be built from source, even if there is a system install.
  # For most packages, the most recent version will work.
  #
  # Note: the following packages have versions or variants that may
  # need changing for your local system.
  #
  #   1. dyninst -- the latest hpctoolkit release should work with the
  #   latest dyninst release.  But if you're building hpctoolkit at
  #   master or develop, then you may need dyninst master.
  #
  #   2. intel-tbb -- add '~tm' for AMD, Xeon Phi (KNL, etc), and very
  #   old Intel systems that don't support transactional memory.
  #
  # Blue Gene is no longer supported.
  #
  #------------------------------------------------------------


  # hpctoolkit -- these settings can be specified here or else on the
  # spack install command line.
  #
  # Version 'develop' is now the main line of development for
  # recommended versions.
  #
  # +mpi builds hpcprof-mpi (requires mpi).
  # +papi uses papi instead of perfmon (now default).
  # +viewer also installs hpcviewer (default).
  # +cuda, +rocm for GPU support.
  #
  # Note: +mpi is currently disabled for develop.
  #
  # hpctoolkit:
  #   version:  [2023.08.0, develop]
  #   variants: +papi +viewer


  # hpcviewer -- hpctoolkit databases are platform independent, so the
  # viewer can be installed together with hpctoolkit, or by itself on
  # another machine.
  #
  # Hpctoolkit 2022.10.01 requires hpcviewer >= 2022.10 due to format
  # change in the database.
  #
  # Note: for technical reasons, "2022.10" should be quoted to avoid
  # being misinterpreted as the number 2022.1.  This applies to all
  # 2-field numbers ending with "0".
  #
  hpcviewer:
    version: [2023.07]


  # binutils -- only used for old versions
  #
  # +libiberty is needed for xmalloc functions in libbfd.
  # ~nls is used to avoid building gettext.
  #
  # binutils:
  #   version:  [2.38]
  #   variants: +libiberty ~nls


  # boost -- used by dyninst and now in hpcstruct.
  #
  # Dyninst requires >= 1.67.
  #   1.72.0 is good for older versions of dyninst.
  #   1.77.0 is good for recent dyninst.
  #   avoid 1.68.0, it breaks the build for hpctoolkit.
  #
  # +atomic, +chrono, etc are for dyninst.
  # +graph, +regex, etc are for toolkit proper.
  # ~debug is to build release (optimized) variant.
  # visibility=global is required for recent hpctoolkit.
  #
  # Note: boost now turns off all libraries by default and expects
  # each package to add what it needs.  So, the best practice is to
  # add everything that we use and not disable anything so as not to
  # interfere with another package's needs.
  #
  boost:
    version:  [1.81.0]
    variants: >
      +atomic +chrono +date_time +filesystem +system +thread +timer
      +graph +regex +shared +multithreaded
      visibility=global


  # bzip2 -- used by elfutils to read compressed sections
  #
  # Bzip2 has resumed development, anything after 1.0.6 is good.
  #
  bzip2:
    version:  [1.0.8]
    variants: +shared


  # dyninst -- used in hpcstruct for line map info, inline sequences
  # and loop analysis.  Hpctoolkit and Dyninst work closely together
  # and Dyninst issues releases infrequently, so sometimes it's
  # necessary to use master for the best results.
  #
  # Latest hpctoolkit needs > 12.0.0.  Several problems were discovered
  # in dyninst 11.0.0 that caused failures in hpcstruct.
  #
  # +openmp is to support openmp threads in parseapi.
  #
  dyninst:
    version:  [12.3.0, master]
    variants: +openmp build_type=RelWithDebInfo


  # elfutils -- used by dyninst for reading ELF sections.
  #
  # Dyninst requires >= 0.173 and we want a recent version for best
  # support for output from current compilers.
  # 0.184 fixes a bug in binaries compiled with gcc 11.x.
  # dyninst 12.0.1 requires latest elfutils >= 0.186.
  #
  # +bzip2, +xz no longer exist (always on)
  # ~nls is used to avoid building gettext.
  #
  elfutils:
    version:  [0.189]
    variants: ~nls


  # intel-tbb -- used by dyninst as part of parallel parsing.
  #
  # Use 2020.3 for now, dyninst master can handle later versions, but
  # not 12.3.0 release.
  #
  # Note: add ~tm for very old x86 or AMD or KNL systems that don't
  # support transactional memory (no-op on non-x86).
  #
  intel-tbb:
    version:  [2020.3]
    variants: +shared +tm


  # intel-xed -- used in various places to parse x86 instructions
  # (used on x86 only).
  #
  # Xed now has releases but changes very slowly.  Normally use the
  # latest release for best results.
  #
  # +debug adds debug symbols (-g).
  # +pic is now required to link with hpcrun
  #
  intel-xed:
    version:  [2023.04.16]
    variants: +debug +pic


  # libdwarf -- only used for old versions
  #
  # libdwarf:
  #   version:  [20180129]


  # libiberty -- used in dyninst and hpctoolkit for demangling
  #
  # Any recent version is good.
  #
  # +pic is needed to link with dyninst shared library.
  #
  # Note: need to quote "2.40" to avoid looking like floating point
  # number 2.4 (it's a yaml thing).
  #
  libiberty:
    version:  ["2.40"]
    variants: +pic


  # libmonitor -- used in hpcrun to provide access to an application's
  # processes and threads.
  #
  # Normally need the most recent snapshot or master.
  #
  # +hpctoolkit is needed for features specific to hpctoolkit (client
  # signals).
  # ~dlopen is needed for 2021.02 and later.
  #
  libmonitor:
    version:  [2023.02.13, master]
    variants: +hpctoolkit ~dlopen


  # libpfm4 (perfmon) -- used in hpcrun for access to the hardware
  # performance counters.
  #
  # If PAPI is available with the perfmon headers, then that
  # supersedes perfmon.  Otherwise, perfmon provides the perf sample
  # source but not PAPI.
  #
  # Normally want the latest version to support recent CPU types.
  #
  libpfm4:
    version:  [4.13.0]


  # libunwind -- used in hpcrun to help with unwinding.
  #
  # Normally want the most recent release.
  #
  # +xz is for reading compressed symbol tables.
  # +pic is required for linking with hpcrun.
  #
  libunwind:
    version:  [1.6.2]
    variants: +xz +pic


  # mbedtls -- only used for old versions
  #
  # +pic is required for linking with hpcrun.
  #
  # mbedtls:
  #   version:  [2.27.0]
  #   variants: +pic


  # papi -- used in hpcrun for access to the hardware performance
  # counters.
  #
  # If there is a pre-built PAPI for the compute nodes, then it may be
  # better to use that and replace this with a 'prefix:' or 'modules:'
  # entry (see the section on cmake).  But make sure that the PAPI
  # include directory contains the perfmon headers, or else you can't
  # use both PAPI and perfmon.
  #
  # If building, then use version >= 5.6.0 for the installed perfmon
  # headers.
  #
  papi:
    version:  [6.0.0.1]


  # xerces -- used in hpcprof to read XML.
  #
  # Any recent version is good.
  #
  # transcoder=iconv is needed to avoid linking with libiconv.
  # netaccessor=none is to reduce prereqs.
  #
  xerces-c:
    version:  [3.2.3]
    variants: transcoder=iconv netaccessor=none


  # xz (lzma) -- used by elfutils and libunwind to read compressed
  # sections.
  #
  # Avoid 5.2.7 (hpcrun won't link), but 5.2.10 or later is ok.
  #
  # +pic is required for linking with hpcrun.
  #
  xz:
    version:  [5.2.10]
    variants: +pic


  # yaml-cpp -- now used by develop for writing yaml
  #
  # Use recent version for bug fixes.
  #
  # +shared is required for linking with shared lib
  #
  yaml-cpp:
    version:  [0.7.0]
    variants: +shared build_type=RelWithDebInfo


  # zlib -- used by binutils, elfutils and libdwarf to read compressed
  # sections.
  #
  # Zlib development is stagnant and everything before 1.2.13 is
  # deprecated due to security bugs, so use 1.2.13
  #
  # +optimize is to add -O2.
  #
  zlib:
    version:  [1.2.13]
    variants: +optimize +shared


  #------------------------------------------------------------
  # 2 -- GPU and MPI Packages
  #------------------------------------------------------------

  # Packages in this section can be built from source, but if there is
  # a system install for the compute nodes, then it is normally better
  # to use that.

  # cuda -- nvidia cuda, now in master
  #
  # Requires: 10.x or later, 11.1 preferred.
  # Note: best to use 11.5 or later, assuming the system supports it
  #
  # cuda:
  #   version: [11.6.2]
  #
  # cuda:
  #   externals:
  #   - spec: cuda@11.6.2
  #     prefix: /path/to/cuda-11.6.2/directory

  #------------------------------------------------------------

  # rocm -- amd gpus, now in master
  #
  # Requires: 4.5.x or later, 5.x is preferred
  #
  # If /opt/rocm is available, then the easiest solution is to use
  # that.  In that case, specify four prereqs (hip, hsa-rocr-dev,
  # roctracer-dev, rocprofiler-dev) as externals in packages.yaml.
  # For example, with /opt/rocm-5.0.0, use:
  #
  # packages:
  #   hip:
  #     externals:
  #     - spec: hip@5.0.0
  #       prefix: /opt/rocm-5.0.0
  #
  #   hsa-rocr-dev:
  #     externals:
  #     - spec: hsa-rocr-dev@5.0.0
  #       prefix: /opt/rocm-5.0.0
  #
  #   roctracer-dev:
  #     externals:
  #     - spec: roctracer-dev@5.0.0
  #       prefix: /opt/rocm-5.0.0
  #
  #   rocprofiler-dev:
  #     externals:
  #     - spec: rocprofiler-dev@5.0.0
  #       prefix: /opt/rocm-5.0.0
  #
  # If ROCM is not already installed, then you can build it as part of
  # hpctoolkit.  In either case, build hpctoolkit with:
  #
  #   spack install hpctoolkit +rocm
  #
  # Note: this is all very fluid and subject to change.

  #------------------------------------------------------------

  # MPI -- hpctoolkit always supports profiling MPI applications.
  # Adding MPI here is only for building hpcprof-mpi, the MPI version
  # of hpcprof.
  #
  # Normally, you want MPI from a module (mpich, mvapich, openmpi)
  # that was built for the correct interconnect system for the compute
  # nodes.  Also, for hpcprof-mpi, MPI should be built with GNU
  # gcc/g++ and the same version used to build hpctoolkit (to keep the
  # C++ libraries in sync).
  #
  # openmpi:
  #   externals:
  #   - spec: openmpi@3.1.6
  #     modules:
  #     - OpenMPI/3.1.6
  #   buildable: False


  #------------------------------------------------------------
  # 3 -- System Build Tools
  #------------------------------------------------------------

  # Note: Spack can now search for these packages itself.
  # For example:
  #
  #   spack external find cmake
  #
  # This puts an 'externals:' entry for cmake in ~/.spack/packages.yaml
  # if spack finds cmake on your PATH.  This works for cmake, perl,
  # python (and several other packages).  Look for the field
  # 'Externally Detectable' from 'spack info'.

  #------------------------------------------------------------

  # We require cmake >= 3.4, perl >= 5.x and python >= 3.6.
  # There are three ways to satisfy these requirements: a system
  # installed version (eg, /usr), a module or build from scratch.
  #
  # By default, spack will rebuild these, even if your version is
  # perfectly fine.  If you already have an installed version and
  # prefer to use that instead, then uncomment some entry below and
  # edit to fit your system.
  #
  # Note: these three are all build tools.  They are needed to build
  # hpctoolkit, but we don't need them at run time or link with any
  # libraries.  (Not counting hpcsummary which is a python script.)
  # Note:
  #
  #  1. the 'prefix' entry is the parent directory of 'bin', not the
  #  bin directory itself.
  #
  #  2. the 'spec' entry may be a full spec, including dependency specs.
  #
  #  3. a given package may have multiple spec, module and version
  #  entries.
  #
  #  4. 'buildable: False' is optional.  It tells spack that it must use
  #  a 'prefix' or 'modules' entry, or else fail the build.

  #------------------------------------------------------------

  # cmake -- dyninst requires cmake >= 3.4.x.

  # Example for a system install.  This example says that cmake 3.11.0
  # is available at /usr/bin/cmake.
  # cmake:
  #   externals:
  #   - spec: cmake@3.11.0
  #     prefix: /usr
  #   buildable: False

  # Example for a module.  This example says that cmake 3.7.2 is
  # available from module 'CMake/3.7.2'.  You may specify multiple
  # modules, if needed.
  # cmake:
  #   externals:
  #   - spec: cmake@3.7.2
  #     modules:
  #     - CMake/3.7.2
  #   buildable: False

  # Example spec to build cmake from scratch.
  # +ownlibs, ~qt and ~openssl are to reduce prerequisites.
  # cmake:
  #   version:  [3.12.4]
  #   variants: +ownlibs ~qt ~openssl

  #------------------------------------------------------------

  # perl -- autotools requires perl >= 5.x which most systems have.

  # Example for system perl.
  # perl:
  #   externals:
  #   - spec: perl@5.16.3
  #     prefix: /usr
  #   buildable: False

  # Example spec to build perl.
  # perl:
  #   version:  [5.26.2]

  #------------------------------------------------------------

  # python -- we require python >= 3.6

  # Example for system python.  If you have both python2 and python3,
  # then specify them both as 'python' (a special rule for python).
  # python:
  #   externals:
  #   - spec: python@3.6.5
  #     prefix: /usr
  #   - spec: python@2.7.5
  #     prefix: /usr
  #   buildable: False

  # Example for python module.
  # python:
  #   externals:
  #   - spec: python@3.6.5
  #     modules:
  #     - Python/3.6.5
  #   buildable: False

  # Example spec to build python.
  # ~dbm, etc are to reduce prerequisites.
  # python:
  #   version:  [3.6.5]
  #   variants: ~dbm ~libxml2 ~ssl ~sqlite3 ~tkinter

  #------------------------------------------------------------

  # GCC -- hpctoolkit requires building with GNU gcc/g++.
  # Use version 7.3.x or later.
  #
  # Spack handles compilers specially with the compilers.yaml file.
  # This example is only for building a more recent compiler.

  # gcc:
  #   version:  [8.5.0, 9.3.0, 10.3.0]
